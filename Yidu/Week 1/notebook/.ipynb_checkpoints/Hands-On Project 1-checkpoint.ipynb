{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Master Data Science In 4 Weeks\n",
    "\n",
    "## Hands-On Project 1: The Pipeline of Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this hands-on project, we will show the **Pipeline of Machine Learning Project** using the housing price prediction example. \n",
    "\n",
    "When solving the real data science problem using machine learning techniques, experienced data scientists usually have the following checklist in mind.\n",
    "\n",
    "- Understand the problem and draw the big picture. \n",
    "- Get the data. \n",
    "- **Explore the data**: gain some insights.\n",
    "- **Data preprocessing** and **feature engineering**. \n",
    "- Explore some reasonable **machine learning models** and shortlist the best ones. \n",
    "- **Fine-tune** your models and combine them to get a better one. \n",
    "- Present your solution. \n",
    "- Launch, monitor and maintain your system.  \n",
    "\n",
    "In this project, we will show the pipeline step by step. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Problem Description\n",
    "\n",
    "In this hands-on project, we will show the **Pipeline of Machine Learning Project** using the **housing price prediction** example. The data could be download at [Kaggle](https://www.kaggle.com/c/house-prices-advanced-regression-techniques).\n",
    "\n",
    "The reasons we use this example are following:\n",
    "\n",
    "1. This is a real problem you may meet in your life. For example, if you want to buy a new house, this may help you to estimate the price. \n",
    "2. This dataset is not clean, it's suitable for us to show some common used data cleaning and feature engineering techniques. \n",
    "3. The dataset is suitable for beginners to get start. \n",
    "4. A similar dataset for house price in Singapore could be provided for you to explore by yourself.\n",
    "\n",
    "**Hope you can enjoy it.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Set Up\n",
    "\n",
    "First, we will import some common used libraries in the following four weeks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To support both python 2 and python 3\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import some statics\n",
    "from scipy.stats import skew\n",
    "from scipy.stats.stats import pearsonr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Load Data\n",
    "**Pandas** is the most popular library in Python to handle data frame.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set the relative director for training data\n",
    "root_dir = \".\"\n",
    "train_data_dir = root_dir + \"/datasets/train.csv\"\n",
    "\n",
    "# read the data frame\n",
    "train_data = pd.read_csv(train_data_dir)\n",
    "\n",
    "# Print out some data samples\n",
    "train_data.head()\n",
    "\n",
    "#save index\n",
    "\n",
    "index_array = train_data['Id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Explore the data and gain some insights\n",
    "\n",
    "In this part, we will visualize the dataset to help us to understand the data better. This is one of the most important steps when you try to analyze and understand your problem and data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 2.1 Get a summary of your dataset with one line code\n",
    "\n",
    "In pandas, there is a very useful function called **describe()**, this function can generate a summary for the dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data.columns)\n",
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Look at the distribution of target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams['figure.figsize'] = (6.0, 6.0)\n",
    "train_data['SalePrice'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the **SalePrice** is skewed. We will see later how can we handle this. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Explore some relations between selected features and target variable\n",
    "\n",
    "Correlation is a statistical value to imply the linear relationship between two variables. One way to explore the relations between features and target variable is to visualize the correlation between features and target variable. This is just a very rough idea, since correlations can only imply the **linear relationships** between two variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saleprice correlation matrix\n",
    "corrmat = train_data.loc[:,'MSSubClass':'SalePrice'].corr()\n",
    "k = 10 #number of variables for heatmap\n",
    "cols = corrmat.nlargest(k, 'SalePrice')['SalePrice'].index\n",
    "cm = np.corrcoef(train_data[cols].values.T)\n",
    "sns.set(font_scale=1.25)\n",
    "hm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although this is a very rough exporation, we still see that there are some meaningful features which agree with our common sense, for example, **Overall Quality, GrLivArea, Year Built**. Below, we visualize one of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scatter plot grlivarea/saleprice\n",
    "var = 'GrLivArea'\n",
    "train_data.plot(kind='scatter', x = var, y = 'SalePrice')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Data preprocessing and feature engineering\n",
    "\n",
    "Data preprocessing and feature engineering are extremely important in data science projects. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Separate Features and Target Variables\n",
    "\n",
    "X_train = train_data.loc[:, 'MSSubClass':'SaleCondition']\n",
    "y_train = train_data['SalePrice']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Handle Categorical Features\n",
    "\n",
    "Usually, we need to convert categorical features to numerical values. Instead of naively convert them to a sequence of integers, a common used idea is **One-hot-encoding**. In **Pandas**, there is a method called **get_dummies** to do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.get_dummies(X_train)\n",
    "\n",
    "# Visualize\n",
    "X_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Missing Data\n",
    "\n",
    "Missing data(usually indicated as **nan** in data matrix) is a common noise in real datasets, if we do not handle missing data, we need to drop the samples with **nan** values in training data, since we cannot do numerical computations for **nan** values. In test data, this is a disaster, because it means we cannot predict the value of corresponding target variable. \n",
    "\n",
    "In general, we can classfy the preprocessing strategies into two categories. \n",
    "\n",
    "**Naive Idea**: Drop the features with missing data. This is not a wise idea, but sometimes it works if you are confident that the corresponding feature is not important for prediction. \n",
    "\n",
    "**Popular Idea**: Imputation. We can replace the missing data with some statistics, like mean or median. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#filling NA's with the mean of the column:\n",
    "X_train = X_train.fillna(X_train.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Handle Skewed Data\n",
    "\n",
    "One popular way to handle the skewed positive data is to take the logorithm. Just like the figure we show in data exploration part, this will make the data more normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams['figure.figsize'] = (12.0, 6.0)\n",
    "prices = pd.DataFrame({\"price\":train_data[\"SalePrice\"], \"log(price + 1)\":np.log1p(train_data[\"SalePrice\"])})\n",
    "prices.hist()\n",
    "y_train = np.log1p(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Handle other skewed features.  \n",
    "numerical_feats = X_train.dtypes[X_train.dtypes != \"object\"].index\n",
    "\n",
    "# compute skewness of the numerical features\n",
    "skewed_feats = X_train[numerical_feats].apply(lambda x: skew(x.dropna()))\n",
    "skewed_feats = skewed_feats[skewed_feats > 0.75]\n",
    "skewed_feats = skewed_feats.index\n",
    "X_train[skewed_feats] = np.log1p(X_train[skewed_feats])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Training Datasets into Training set and Validation set. \n",
    "\n",
    "This is very important, experienced data scientists always do this. What we really care about is the accuracy of the model on unseen data. Usually, the test data is not available when we train the model. So, in order to evaluate the performance of your machine learning model on unseen data and preventing overfitting, we usually split the training set into two datasets randomly, using part of the training data as **validation data(10% - 20%)**. If the training data is limited, then we usually do **cross-validation**. There are **train_test_split** function in **Scikit Learn**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# But if you use scikit learn, cross-validation is built-in method\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val, train_id, val_id = train_test_split(X_train, y_train, index_array,test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore some reasonable models\n",
    "\n",
    "Usually, after you prepared your data, you will begin to try some reasonable machine learning model to solve your problem. In this problem, we will try **Linear Regression**, **Linear Regression with Regularization(Ridge Regression, Lasso)**, **Decision Tree**, **XGBoost** models. \n",
    "\n",
    "The most fundamental model called **Linear Regression**, which has the fllowing form:\n",
    "$$\\frac{1}{2}\\sum_{i=1}^n[(y_i - \\sum_{j=1}^d X_{ij}w_j)^2]$$\n",
    "Or, we can write it in the following compact matrix form\n",
    "$$\\min_{w} \\frac{1}{2}\\|y_{train} - X_{train}w\\|_2^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "model_linear_reg = LinearRegression()\n",
    "\n",
    "# Train your Linear Regression Model on Training Set\n",
    "model_linear_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yeah, you get your first Machine Learning Model\n",
    "# Print out some values \n",
    "\n",
    "data_sample = X_train.iloc[100:105]\n",
    "y_sample = y_train.iloc[100:105]\n",
    "print(\"Predictions: \\t\", model_linear_reg.predict(data_sample))\n",
    "print(\"True Labels: \\t\", np.array(y_sample))\n",
    "\n",
    "# compute the mean-square error on training set\n",
    "y_pred_linear_reg = model_linear_reg.predict(X_train)\n",
    "mse_model_linear_reg = mean_squared_error(y_train, y_pred_linear_reg)\n",
    "print(\"The Mean-Square-Error of the linear regression model is:\", mse_model_linear_reg)\n",
    "# It seems not that bad!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the learned parameters we get\n",
    "\n",
    "print(\"The value of w is:\", model_linear_reg.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularization\n",
    "\n",
    "We can see that, the values of all parameters are nonzeros. However, we know there are some features in the dataset that are not benifit for us to predict the price of the house. In other words, we want to do the feature selections to get the useful features automatically. One popular way to achieve this goal is to add a regularization term $\\|\\cdot\\|_1$ which can enforce the parameters to be sparse. \n",
    "\n",
    "Later, you will learn the regularization term from the aspect of preventing over-fitting. \n",
    "\n",
    "So, in order to do feature selection, we will consider the following regularized linear model, called **Lasso**:\n",
    "$$\\min_{w} \\frac{1}{2}\\|y_{train} - X_{train}w\\|_2^2 + \\alpha \\|w\\|_1$$\n",
    "where $\\alpha >0$ is the hyperparameter to control the strength of the regularization term. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "model_lasso = Lasso(alpha = 0.01, max_iter= 4000)\n",
    "\n",
    "# choose the value of your hyperparameter alpha\n",
    "# Train your model\n",
    "model_lasso.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out some results to see the performance\n",
    "data_sample = X_train.iloc[100:105]\n",
    "y_sample = y_train.iloc[100:105]\n",
    "print(\"Predictions: \\t\", model_lasso.predict(data_sample))\n",
    "print(\"True Labels: \\t\", np.array(y_sample))\n",
    "\n",
    "y_pred_lasso = model_lasso.predict(X_train)\n",
    "mse_model_lasso = mean_squared_error(y_train, y_pred_lasso)\n",
    "print(\"The Mean-Square-Error of the Lasso model is:\", mse_model_lasso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you look at the results and compare them to the predictions we get from linear regression, you can see that the performance is worse. This is contradict to your common sense since we should get better results if we exclude some irrelavent features. \n",
    "\n",
    "**Analysis**: The problem maybe we select a inappropriate hyperparameter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lasso_2 = Lasso(alpha= 0.0002, max_iter= 4000)\n",
    "model_lasso_2.fit(X_train, y_train)\n",
    "\n",
    "# print out something\n",
    "data_sample = X_train.iloc[100:105]\n",
    "y_sample = y_train.iloc[100:105]\n",
    "print(\"Predictions: \\t\", model_lasso_2.predict(data_sample))\n",
    "print(\"True Labels: \\t\", np.array(y_sample))\n",
    "\n",
    "y_pred_lasso_2 = model_lasso_2.predict(X_train)\n",
    "mse_model_lasso_2 = mean_squared_error(y_train, y_pred_lasso_2)\n",
    "print(\"The Mean-Square-Error of the new lasso model is:\", mse_model_lasso_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### A better way to evaluate the performance of your machine learning model\n",
    "\n",
    "In real project, what we really care about is the testing error. However, we cannot evaluate our machine learning model on the test dataset before we launch our model. One possible way to estimate the performance of our model on unseen data is cross-validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "def rmse_cv(model):\n",
    "    rmse= np.sqrt(-cross_val_score(model, X_train, y_train, scoring=\"neg_mean_squared_error\", cv = 5))\n",
    "    return(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = [0.01, 0.0002]\n",
    "cv_lasso = [rmse_cv(Lasso(alpha = alpha, max_iter= 4000)).mean() \n",
    "            for alpha in alphas]\n",
    "cv_lasso = pd.Series(cv_lasso, index = alphas)\n",
    "print(\"Cross Validation Error for Lasso:\", cv_lasso)\n",
    "#cv_lasso.plot(title = \"Validation Error\")\n",
    "#plt.xlabel(\"alpha\")\n",
    "#plt.ylabel(\"rmse\")\n",
    "\n",
    "cv_linear_reg = rmse_cv(model_linear_reg).mean()\n",
    "print(\"Cross Validation Error for Linear Regression:\", cv_linear_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The smallest validation error is:\",(cv_lasso.min()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we try to explore more linear models. \n",
    "In high-dimensional problem, we usually want to get a sparse solution, One popular model to get the sparse solution is Lasso. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lasso_better = Lasso(alpha= 0.0002, max_iter= 4000)\n",
    "model_lasso_better.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we check whether Lasso has the ability to do feature selection or not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef = pd.Series(model_lasso_better.coef_, index = X_train.columns)\n",
    "print(\"Lasso picked \" + str(sum(coef != 0)) + \" variables and eliminated the other \" +  str(sum(coef == 0)) + \" variables\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we try to check whether the Lasso model selected the meaningful features or not. To do this, we visualize the important features selected by Lasso model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_coef = pd.concat([coef.sort_values().head(10),\n",
    "                     coef.sort_values().tail(10)])\n",
    "\n",
    "# Visualize them.\n",
    "matplotlib.rcParams['figure.figsize'] = (8.0, 10.0)\n",
    "imp_coef.plot(kind = \"barh\")\n",
    "plt.title(\"Important Coefficients in the Lasso Model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tune Your Machine Learning Model\n",
    "\n",
    "Now, we have some models in hand. However, we want to fine tune our machine learning model to get better results. Usually, we will fine tune our model in two ways:\n",
    "\n",
    "- **Hyperparameter Tuning**: From the example showed in Lasso model, when the hyperparameters are not selected appropriately, we may get poor results. \n",
    "\n",
    "- **Model Ensemble**: In the idea of ensemble, you will combine some short-listed models together via weighted average to get better results. This is commonly used in real problems. One intuitive reason why ensemble could get a better result is, ensemble can reduce the variance of the single models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search\n",
    "\n",
    "How to do **Hyperparameter Tuning** is very problem dependent. Some useful ideas are:\n",
    "\n",
    "1. Try some descrete values to determine the rough range of the hyperparameters. \n",
    "2. Use Grid Search or Random Search to fine tune your hyperparameters in the range. \n",
    "\n",
    "To do Grid search, you can get Scikit-Learn’s GridSearchCV to search for you. All you need to do is tell it which\n",
    "hyperparameters you want it to experiment with, and what values to try out, and it will evaluate all the\n",
    "possible combinations of hyperparameter values, using cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "    {'alpha':np.arange(0.0001,0.01,0.0002)}\n",
    "]\n",
    "\n",
    "model_lasso_cv = Lasso(max_iter=4000)\n",
    "\n",
    "grid_search = GridSearchCV(model_lasso_cv, param_grid, cv = 5, scoring = 'neg_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find the best parameters\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Use the best One \n",
    "model_lasso_best = grid_search.best_estimator_\n",
    "print(\"Cross_Validation rmse is:\", rmse_cv(model_lasso_best).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Results on Test Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_linear_reg = model_linear_reg.predict(X_val)\n",
    "y_pred_lasso = model_lasso_best.predict(X_val)\n",
    "\n",
    "print(\"The Mean-Square-Error of the linear regression model is:\", mean_squared_error(y_val, y_pred_linear_reg))\n",
    "print(\"The Mean-Square-Error of the  lasso model is:\", mean_squared_error(y_val, y_pred_lasso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution = pd.DataFrame({\"id\":val_id, \"SalePrice\":y_pred_lasso})\n",
    "solution.to_csv(\"lasso_sol.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
